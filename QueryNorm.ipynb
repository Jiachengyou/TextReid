{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(a_list, b_list):\n",
    "    return float(len(set(a_list) & set(b_list))) / float(len(set(a_list) | set(b_list)))\n",
    "\n",
    "\n",
    "def jaccard_mat(row_nn, col_nn):\n",
    "    jaccard_sim = np.zeros((row_nn.shape[0], col_nn.shape[0]))\n",
    "    # FIXME: need optimization\n",
    "    for i in range(row_nn.shape[0]):\n",
    "        for j in range(col_nn.shape[0]):\n",
    "            jaccard_sim[i, j] = jaccard(row_nn[i], col_nn[j])\n",
    "    return torch.from_numpy(jaccard_sim)\n",
    "def rank(similarity, q_pids, g_pids, topk=[1, 5, 10], get_mAP=True):\n",
    "    max_rank = max(topk)\n",
    "    if get_mAP:\n",
    "        indices = torch.argsort(similarity, dim=1, descending=True)\n",
    "    else:\n",
    "        # acclerate sort with topk\n",
    "        _, indices = torch.topk(\n",
    "            similarity, k=max_rank, dim=1, largest=True, sorted=True\n",
    "        )  # q * topk\n",
    "    pred_labels = g_pids[indices]  # q * k\n",
    "    matches = pred_labels.eq(q_pids.view(-1, 1))  # q * k\n",
    "\n",
    "    all_cmc = matches[:, :max_rank].cumsum(1)\n",
    "    all_cmc[all_cmc > 1] = 1\n",
    "    all_cmc = all_cmc.float().mean(0) * 100\n",
    "    all_cmc = all_cmc[topk - 1]\n",
    "\n",
    "    if not get_mAP:\n",
    "        return all_cmc, indices\n",
    "\n",
    "    num_rel = matches.sum(1)  # q\n",
    "    tmp_cmc = matches.cumsum(1)  # q * k\n",
    "    tmp_cmc = [tmp_cmc[:, i] / (i + 1.0) for i in range(tmp_cmc.shape[1])]\n",
    "    tmp_cmc = torch.stack(tmp_cmc, 1) * matches\n",
    "    AP = tmp_cmc.sum(1) / num_rel  # q\n",
    "    mAP = AP.mean() * 100\n",
    "    return all_cmc, mAP, indices\n",
    "def k_reciprocal(q_feats, g_feats, neighbor_num=5, alpha=0.05):\n",
    "    qg_sim = torch.matmul(q_feats, g_feats.t())  # q * g\n",
    "    gg_sim = torch.matmul(g_feats, g_feats.t())  # g * g\n",
    "\n",
    "    qg_indices = torch.argsort(qg_sim, dim=1, descending=True)\n",
    "    gg_indices = torch.argsort(gg_sim, dim=1, descending=True)\n",
    "\n",
    "    qg_nn = qg_indices[:, :neighbor_num]  # q * n\n",
    "    gg_nn = gg_indices[:, :neighbor_num]  # g * n\n",
    "\n",
    "    jaccard_sim = jaccard_mat(qg_nn.cpu().numpy(), gg_nn.cpu().numpy())  # q * g\n",
    "    jaccard_sim = jaccard_sim.to(qg_sim.device)\n",
    "    return alpha * jaccard_sim  # q * g\n",
    "\n",
    "def k_reciprocal_update(qg_sim, g_feats, neighbor_num=5, alpha=0.05):\n",
    "    gg_sim = torch.matmul(g_feats, g_feats.t())  # g * g\n",
    "\n",
    "    qg_indices = torch.argsort(qg_sim, dim=1, descending=True)\n",
    "    gg_indices = torch.argsort(gg_sim, dim=1, descending=True)\n",
    "\n",
    "    qg_nn = qg_indices[:, :neighbor_num]  # q * n\n",
    "    gg_nn = gg_indices[:, :neighbor_num]  # g * n\n",
    "\n",
    "    jaccard_sim = jaccard_mat(qg_nn.cpu().numpy(), gg_nn.cpu().numpy())  # q * g\n",
    "    jaccard_sim = jaccard_sim.to(qg_sim.device)\n",
    "    return alpha * jaccard_sim  # q * g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import numpy as np\n",
    "args = dict()\n",
    "args['k'] = 1\n",
    "args['beta'] = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns list of retrieved top k videos based on the sims matrix\n",
    "def get_retrieved_videos(sims, k):\n",
    "    argm = np.argsort(-sims, axis=1)\n",
    "    topk = argm[:,:k].reshape(-1)\n",
    "    retrieved_videos = np.unique(topk)\n",
    "    return retrieved_videos\n",
    "\n",
    "# Returns list of indices to normalize from sims based on videos\n",
    "def get_index_to_normalize(sims, videos):\n",
    "    argm = np.argsort(-sims, axis=1)[:,0]\n",
    "    result = np.array(list(map(lambda x: x in videos, argm)))\n",
    "    result = np.nonzero(result)\n",
    "    return result\n",
    "\n",
    "def qb_norm(train_test, test_test, args):\n",
    "    k = args.get(\"k\", 1)\n",
    "    beta = args.get(\"beta\", 20)\n",
    "    retrieved_videos = get_retrieved_videos(train_test, k)\n",
    "    test_test_normalized = test_test.copy()\n",
    "    train_test = np.exp(train_test*beta)\n",
    "    test_test = np.exp(test_test*beta)\n",
    "\n",
    "    normalizing_sum = np.sum(train_test, axis=0)\n",
    "    index_for_normalizing = get_index_to_normalize(test_test, retrieved_videos)\n",
    "    test_test_normalized[index_for_normalizing, :] = \\\n",
    "        np.divide(test_test[index_for_normalizing, :], normalizing_sum)\n",
    "    return test_test_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'train_text.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_41271/1918864244.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train_text.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test_text.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test_image.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/txtreid/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train_text.npy'"
     ]
    }
   ],
   "source": [
    "train_text = np.load(\"train_text.npy\")\n",
    "test_text = np.load(\"test_text.npy\")\n",
    "test_image = np.load(\"test_image.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test = np.matmul(train_text, test_image.T)\n",
    "test_test = np.matmul(test_text, test_image.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((68126, 3074), (6156, 3074))"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test.shape,test_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.79221576, 0.7817477 , 0.7255626 , ..., 0.11330012, 0.12920153,\n",
       "        0.09065817],\n",
       "       [0.81690973, 0.81889147, 0.7599835 , ..., 0.06901371, 0.08979727,\n",
       "        0.05566901],\n",
       "       [0.5925783 , 0.6066235 , 0.5384193 , ..., 0.12045822, 0.15623726,\n",
       "        0.15992202],\n",
       "       ...,\n",
       "       [0.10873044, 0.15870313, 0.04203584, ..., 0.80582166, 0.79874676,\n",
       "        0.62822354],\n",
       "       [0.06607162, 0.09906943, 0.00132245, ..., 0.50819975, 0.5425391 ,\n",
       "        0.6256979 ],\n",
       "       [0.02234511, 0.03662704, 0.00830404, ..., 0.20784797, 0.25536132,\n",
       "        0.5221216 ]], dtype=float32)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_test_copy = test_test.copy()\n",
    "test_test_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_test_normalized = qb_norm(train_test, test_test, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   0,    0,    0, ..., 6155, 6155, 6155]),\n",
       " array([   0,    1,    2, ..., 3071, 3072, 3073]))"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nonzero(test_test_normalized != test_test_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "topk = torch.tensor([1,5,10])\n",
    "text_pid = np.load(\"text_pid.npy\")\n",
    "image_pid = np.load(\"image_pid.npy\")\n",
    "t2i_cmc, _ = rank(torch.tensor(test_test_normalized), torch.tensor(text_pid), torch.tensor(image_pid), topk, get_mAP=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "tensor([59.2593, 77.2904, 84.6004])\n",
      "11\n",
      "tensor([59.4217, 77.5666, 84.7466])\n",
      "12\n",
      "tensor([59.5517, 77.6803, 84.8765])\n",
      "13\n",
      "tensor([59.6816, 77.7778, 84.9415])\n",
      "14\n",
      "tensor([59.6979, 77.8752, 84.9253])\n",
      "15\n",
      "tensor([59.6654, 77.9077, 85.0065])\n",
      "16\n",
      "tensor([59.7303, 77.9890, 85.0715])\n",
      "17\n",
      "tensor([59.6654, 78.0052, 84.8928])\n",
      "18\n",
      "tensor([59.7303, 77.9727, 84.9578])\n",
      "19\n",
      "tensor([59.5679, 77.8752, 85.1040])\n"
     ]
    }
   ],
   "source": [
    "for i in range(10,20,1):\n",
    "    args['beta'] = i\n",
    "    print(i)\n",
    "    test_test_normalized = qb_norm(train_test, test_test, args)\n",
    "    t2i_cmc, _ = rank(torch.tensor(test_test_normalized), torch.tensor(text_pid), torch.tensor(image_pid), topk, get_mAP=False)\n",
    "    print(t2i_cmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([57.2612, 76.4457, 84.3405])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rvn_mat = k_reciprocal_update(torch.tensor(test_test_normalized), torch.tensor(test_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.80003065,  0.77750695,  0.7724082 , ...,  0.152077  ,\n",
       "         0.16015589,  0.07175662],\n",
       "       [ 0.78522956,  0.7851329 ,  0.7709395 , ...,  0.15204026,\n",
       "         0.15973394,  0.05422914],\n",
       "       [ 0.48401484,  0.52995706,  0.43170282, ...,  0.10086777,\n",
       "         0.1578648 ,  0.11296237],\n",
       "       ...,\n",
       "       [ 0.21264191,  0.2570559 ,  0.1500122 , ...,  0.70756483,\n",
       "         0.7190536 ,  0.646068  ],\n",
       "       [ 0.10210612,  0.12128984, -0.00372251, ...,  0.3991889 ,\n",
       "         0.48524168,  0.5229347 ],\n",
       "       [-0.12080702, -0.10585881, -0.18819067, ...,  0.14036119,\n",
       "         0.21350087,  0.35388976]], dtype=float32)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(1,30,1):\n",
    "    re_t2i_cmc, re_t2i_mAP, _ = rank(\n",
    "                torch.tensor(rvn_mat) + i*torch.tensor(test_test_normalized), torch.tensor(text_pid), torch.tensor(image_pid), topk, get_mAP=True\n",
    "            )\n",
    "    print(i)\n",
    "    print(re_t2i_cmc, re_t2i_mAP)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "txtreid",
   "language": "python",
   "name": "txtreid"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
