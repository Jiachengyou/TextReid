{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank(similarity, q_pids, g_pids, topk=[1, 5, 10], get_mAP=True):\n",
    "    max_rank = max(topk)\n",
    "    if get_mAP:\n",
    "        indices = torch.argsort(similarity, dim=1, descending=True)\n",
    "    else:\n",
    "        # acclerate sort with topk\n",
    "        _, indices = torch.topk(\n",
    "            similarity, k=max_rank, dim=1, largest=True, sorted=True\n",
    "        )  # q * topk\n",
    "    pred_labels = g_pids[indices]  # q * k\n",
    "    matches = pred_labels.eq(q_pids.view(-1, 1))  # q * k\n",
    "\n",
    "    all_cmc = matches[:, :max_rank].cumsum(1)\n",
    "    all_cmc[all_cmc > 1] = 1\n",
    "    all_cmc = all_cmc.float().mean(0) * 100\n",
    "    all_cmc = all_cmc[topk - 1]\n",
    "\n",
    "    if not get_mAP:\n",
    "        return all_cmc, indices\n",
    "\n",
    "    num_rel = matches.sum(1)  # q\n",
    "    tmp_cmc = matches.cumsum(1)  # q * k\n",
    "    tmp_cmc = [tmp_cmc[:, i] / (i + 1.0) for i in range(tmp_cmc.shape[1])]\n",
    "    tmp_cmc = torch.stack(tmp_cmc, 1) * matches\n",
    "    AP = tmp_cmc.sum(1) / num_rel  # q\n",
    "    mAP = AP.mean() * 100\n",
    "    return all_cmc, mAP, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import numpy as np\n",
    "args = dict()\n",
    "args['k'] = 1\n",
    "args['beta'] = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns list of retrieved top k videos based on the sims matrix\n",
    "def get_retrieved_videos(sims, k):\n",
    "    argm = np.argsort(-sims, axis=1)\n",
    "    topk = argm[:,:k].reshape(-1)\n",
    "    retrieved_videos = np.unique(topk)\n",
    "    return retrieved_videos\n",
    "\n",
    "# Returns list of indices to normalize from sims based on videos\n",
    "def get_index_to_normalize(sims, videos):\n",
    "    argm = np.argsort(-sims, axis=1)[:,0]\n",
    "    result = np.array(list(map(lambda x: x in videos, argm)))\n",
    "    result = np.nonzero(result)\n",
    "    return result\n",
    "\n",
    "def qb_norm(train_test, test_test, args):\n",
    "    k = args.get(\"k\", 1)\n",
    "    beta = args.get(\"beta\", 20)\n",
    "    retrieved_videos = get_retrieved_videos(train_test, k)\n",
    "    test_test_normalized = test_test.copy()\n",
    "    train_test = np.exp(train_test*beta)\n",
    "    test_test = np.exp(test_test*beta)\n",
    "\n",
    "    normalizing_sum = np.sum(train_test, axis=0)\n",
    "    index_for_normalizing = get_index_to_normalize(test_test, retrieved_videos)\n",
    "    test_test_normalized[index_for_normalizing, :] = \\\n",
    "        np.divide(test_test[index_for_normalizing, :], normalizing_sum)\n",
    "    return test_test_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = np.load(\"train_text.npy\")\n",
    "test_text = np.load(\"test_text.npy\")\n",
    "test_image = np.load(\"test_image.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test = np.matmul(train_text, test_image.T)\n",
    "test_test = np.matmul(test_text, test_image.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((68126, 3074), (6156, 3074))"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test.shape,test_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.79221576, 0.7817477 , 0.7255626 , ..., 0.11330012, 0.12920153,\n",
       "        0.09065817],\n",
       "       [0.81690973, 0.81889147, 0.7599835 , ..., 0.06901371, 0.08979727,\n",
       "        0.05566901],\n",
       "       [0.5925783 , 0.6066235 , 0.5384193 , ..., 0.12045822, 0.15623726,\n",
       "        0.15992202],\n",
       "       ...,\n",
       "       [0.10873044, 0.15870313, 0.04203584, ..., 0.80582166, 0.79874676,\n",
       "        0.62822354],\n",
       "       [0.06607162, 0.09906943, 0.00132245, ..., 0.50819975, 0.5425391 ,\n",
       "        0.6256979 ],\n",
       "       [0.02234511, 0.03662704, 0.00830404, ..., 0.20784797, 0.25536132,\n",
       "        0.5221216 ]], dtype=float32)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_test_copy = test_test.copy()\n",
    "test_test_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_test_normalized = qb_norm(train_test, test_test, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   0,    0,    0, ..., 6155, 6155, 6155]),\n",
       " array([   0,    1,    2, ..., 3071, 3072, 3073]))"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nonzero(test_test_normalized != test_test_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "topk = torch.tensor([1,5,10])\n",
    "text_pid = np.load(\"text_pid.npy\")\n",
    "image_pid = np.load(\"image_pid.npy\")\n",
    "t2i_cmc, _ = rank(torch.tensor(test_test_normalized), torch.tensor(text_pid), torch.tensor(image_pid), topk, get_mAP=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "tensor([59.2593, 77.2904, 84.6004])\n",
      "11\n",
      "tensor([59.4217, 77.5666, 84.7466])\n",
      "12\n",
      "tensor([59.5517, 77.6803, 84.8765])\n",
      "13\n",
      "tensor([59.6816, 77.7778, 84.9415])\n",
      "14\n",
      "tensor([59.6979, 77.8752, 84.9253])\n",
      "15\n",
      "tensor([59.6654, 77.9077, 85.0065])\n",
      "16\n",
      "tensor([59.7303, 77.9890, 85.0715])\n",
      "17\n",
      "tensor([59.6654, 78.0052, 84.8928])\n",
      "18\n",
      "tensor([59.7303, 77.9727, 84.9578])\n",
      "19\n",
      "tensor([59.5679, 77.8752, 85.1040])\n"
     ]
    }
   ],
   "source": [
    "for i in range(10,20,1):\n",
    "    args['beta'] = i\n",
    "    print(i)\n",
    "    test_test_normalized = qb_norm(train_test, test_test, args)\n",
    "    t2i_cmc, _ = rank(torch.tensor(test_test_normalized), torch.tensor(text_pid), torch.tensor(image_pid), topk, get_mAP=False)\n",
    "    print(t2i_cmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([57.2612, 76.4457, 84.3405])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2i_cmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.80003065,  0.77750695,  0.7724082 , ...,  0.152077  ,\n",
       "         0.16015589,  0.07175662],\n",
       "       [ 0.78522956,  0.7851329 ,  0.7709395 , ...,  0.15204026,\n",
       "         0.15973394,  0.05422914],\n",
       "       [ 0.48401484,  0.52995706,  0.43170282, ...,  0.10086777,\n",
       "         0.1578648 ,  0.11296237],\n",
       "       ...,\n",
       "       [ 0.21264191,  0.2570559 ,  0.1500122 , ...,  0.70756483,\n",
       "         0.7190536 ,  0.646068  ],\n",
       "       [ 0.10210612,  0.12128984, -0.00372251, ...,  0.3991889 ,\n",
       "         0.48524168,  0.5229347 ],\n",
       "       [-0.12080702, -0.10585881, -0.18819067, ...,  0.14036119,\n",
       "         0.21350087,  0.35388976]], dtype=float32)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_test = test_test_copy.copy()\n",
    "test_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.07206351,  0.06216157,  0.06284328, ...,  0.25377652,\n",
       "         0.20778054,  0.18290631],\n",
       "       [ 0.0627052 ,  0.07563372,  0.09879597, ...,  0.12553865,\n",
       "         0.10225028,  0.11241295],\n",
       "       [ 0.00257592,  0.01570105,  0.03701405, ...,  0.2815793 ,\n",
       "         0.3008128 ,  0.16156209],\n",
       "       ...,\n",
       "       [ 0.20475474,  0.14967012,  0.23735371, ..., -0.12485246,\n",
       "        -0.10914449, -0.16367406],\n",
       "       [ 0.13384305,  0.10074963,  0.10405405, ..., -0.09958716,\n",
       "        -0.08937244, -0.18648036],\n",
       "       [ 0.22390501,  0.20834157,  0.19274658, ...,  0.01956081,\n",
       "        -0.00192396, -0.0893784 ]], dtype=float32)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "txtreid",
   "language": "python",
   "name": "txtreid"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
